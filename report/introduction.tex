\section{Introduction}

Deep Convolutional Neural Networks (CNNs) have become the dominating approach for image classification since ten years ago. Due to tremendous progress has made in recent years, Deep CNNs are allowed to achieve impressive performance on hard visual recognition tasks, exceeding human performance in the image classification domain. A number of new architectures have been proposed, including VGG \cite{simonyan2014very}, NiN \cite{lin2013network}, Inception \cite{chen2017rethinking}, ResNet \cite{he2016deep}, and so on. Meanwhile, we've observed a steady increasing trend of model accuracy \cite{he2019bag}. However, these models typically require abundant labeled training samples, which have the same distribution as the test data. Collecting sufficient training data is usually expensive, time-consuming, or even unrealistic \cite{zhuang2020comprehensive}. Besides, it could be very time-consuming to train the models when it involves a large number of images \cite{hussain2018study}.

Transfer learning \cite{shaha2018transfer}, was introduced to handle these issues, which focuses on improving the efficiency of the target domains by transferring the knowledge from different but related source domains. According to the generalization theory of transfer, learning to transfer is the result of the generalization of experience. In this way, we can reduce the amount of data for training and testing dramatically. At the same time, the training time is also decreased remarkably. 

Moreover, the siamese network \cite{he2018twofold} is another good solution for learning from very little data. It's a classical convolutional neural network architecture that consists of two or more sub-networks. Each sub-network is a complete convolutional neural network, has the same configuration and parameters. They shared the learned weights with each other by updating them mirrored. Unlike the traditional k-NN classification approach, which involves thresholding the distance between the two embeddings, the siamese network involves distances of both the positive embedding and the negative embedding.  In doing so, given a few images per class is sufficient for Siamese Networks to classify those images. Furthermore, for predicting multiple classes, it does not need to update the number of classes and retrain the whole model when the number of classes is changed, like the traditional deep neural network. It learns a similarity function and checks if the two images are the same. 

In this project, we implement both the transfer learning and siamese network approaches to classify a large image dataset. We then further explore the efficiency of the models with varying parameters. We also investigate the effect of different loss functions when applying to the siamese network. At last, we compare the performance and accuracy of models.  