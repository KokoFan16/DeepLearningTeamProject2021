\section{Evaluation}

\subsection{Implementation of Transfer Learning}
In our first implementation, as shown on figure \ref {fig:xceptiona}, we feed an image to Xception model and took the average pooling of the last layer from Xception, and then we used a classification layer directly to classify the image. We used the cross-entropy loss for training. For this approach, we experimented by freezing the weights from Xception and by training it from scratch. 

\begin{figure}[h]
 \centering
  \begin{subfigure}[b]{\linewidth}
 \includegraphics[width=\linewidth]{figs/xception_1.png}
  \caption{Version 1}
  \label{fig:xceptiona}
  \end{subfigure}
    \hfill
  \begin{subfigure}[b]{\linewidth}
 \includegraphics[width=\linewidth]{figs/xception_1.png}
 \caption{Version 2}
  \label{fig:xceptionb}
  \end{subfigure}
    \hfill    
 \caption{Implemented transfer learning architectures.}
 \label{fig:xception}
\end{figure}

On the second implementation, as shown on figure \ref{fig:xceptionb}, we froze learned weights from Xception but we added a fully connected layer before the prediction layer. For this fully connected, We used 512 Victor dimension because we wanted to match it with the best embedding size of our implementation for siamese network for the comparison. 

\subsection{Implementation of Siamese Network}

The architecture of our implementations of the siamese network is shown as figure \ref{fig:model}. Our network consists of a batch input layer and a deep CNN followed by L2 normalization, which results in the image embedding. This is followed by a loss function during training. Note that the siamese network was designed originally for calculating the similarity between images, not the image classification. Normally, it would have a distance function to compute the similarity between the two embedding vectors as the final outputs. However, our project is for the image classification problem, so we add one more fully connected layer on top of that to train the embeddings to generate class output. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/model.png}
  \caption{The architecture of our model.}
  \label{fig:model}
\end{figure}

In this project, we implemented three variants of the siamese network. The first one is with contrastive loss, and the second one is with triplet loss. The third one is the combination of transfer learning and the one with triplet loss.

For contrastive loss, we implement and train siamese networks using Keras and Tensorflow. The implementation can be partitioned into three steps: 1) generating image pairs, 2) construct the architecture of the siamese neural network, 3) using contrastive loss to train the model. We adopt a simple strategy to make the image pairs. The positive sample is picked randomly from the same category as the anchor, and label with 1. On the other hand, we grab the negative sample randomly from classes that are different from the anchor and label it with 0. Figure \ref{fig:pairs} shows the examples the positive and negative paris. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{figs/pairs.png}
  \caption{Examples of anchor, positive and negative samples.}
  \label{fig:pairs}
\end{figure}


\begin{figure}[h]
 \centering
 \includegraphics[width=\linewidth]{figs/cnn.png}
 \caption{A typical Convolutional Neural Network (CNN) architecture.}
 \label{fig:cnn}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/contra_model.png}
  \caption{The model with contrastive loss we built.}
  \label{fig:contra_model}
\end{figure}





%\subsubsection{Implementation of triplet loss}
%We construct the model with triplet loss by calling the TripletSemiHardLoss function in TensorFlow Addons. As shown in the paper \cite{}, the best results are from Semi-Hard triplets. The negative is farther from the anchor than the positive, but still offers a positive loss. Figure \ref{fig:tri_model} illustrates the model. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/tri_model.png}
  \caption{The model with triplet loss we built.}
  \label{fig:tri_model}
\end{figure}

%\subsubsection{Combination of transfer Learning and triplet loss}
%In this project, we also implement an advanced version that combine the transfer learning with triplet loss. We first use the Xception model to extract the embeddings of the three embeddings in a triplet. Then, we added 2 dense layers with the expectation that the triplet loss will improve the features extracted from transfer learning.



\subsection{Comparison and Analysis}

In this section, we first show the training loss for all the models, and we further analyze the effect of different hyperparameters. We then make a comparison of the results of all the models based on both the classification accuracy and the time-consume of training, and meanwhile, we give the possible reasons. Moreover, we not only focus on the overall classification accuracy but also the accuracy of each class. All our experiments are executed on the Cheaha with a single GPU. 

\begin{table}[ht]
    \caption{Summary of the results on 1500 images} 
    \centering 
    \begin{tabular}{c c c c} 
    \hline\hline 
    
    model & Accuracy \% & Epochs & Time (mins)  \\% inserts table
    \hline % inserts single horizontal line
    Xception (T0) & 91.8 & 20 & 1.8 \\% inserting body of the table
    Xception+dense (T1) & 90.7 & 20 & 3.5 \\% inserting body of the table
    Xception All (T2) & 95.1 & 10 & 5.4 \\% inserting body of the table
    Our Siamese+Con. Loss (S0) & 92.57 & 32 & 6 \\% inserting body of the table
    Our Siamese+Triplet. Loss (S1) & 20 & 91.02 & 2 \\% inserting body of the table
    Xception+Siamese (S2) & 95.85 & 10 & 2 \\% inserting body of the table
    \hline 
    \end{tabular}
\label{table:data} % is used to refer this table in the text
\end{table}

\begin{table}[ht]
    \caption{Summary of the results on 2500 images} 
    \centering 
    \begin{tabular}{c c c c} 
    \hline\hline 
    
    model & Accuracy \% & Epochs & Time (mins)  \\% inserts table
    \hline % inserts single horizontal line
    Xception (T0) & 89.9 & 20 & 4 \\% inserting body of the table
    Xception+dense (T1) & 89.3 & 20 & 4 \\% inserting body of the table
    Xception All (T2) & 94.0 & 10 & 6 \\% inserting body of the table
    Our Siamese+Con. Loss (S0) & 90.2 & 32 & 14 \\% inserting body of the table
    Our Siamese+Triplet. Loss (S1) & - & - & - \\% inserting body of the table
    Xception+Siamese (S2) & - & - & - \\% inserting body of the table
    \hline 
    \end{tabular}
\label{table:data} % is used to refer this table in the text
\end{table}

\subsubsection{Tranning Loss}

Figure \ref{fig:siatrainloss} shows the training loss for the three implementations of the siamese network. Figure \ref{ffig:tertrainloss} shows the training loss for the three implementations of the transfer Learning.


\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/transfer_loss.png}
  \caption{Transfer Learning version 1}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/transfer_loss_2.png}
   \caption{Transfer Learning version 2}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/transfer_loss_3.png}
   \caption{Transfer Learning version 3}
   \label{fig:tri_loss_2}
  \end{subfigure}
  \hfill
    \caption{Training loss of the three implementations of transfer Learning.}
    \label{fig:tertrainloss}
\end{figure}


\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/con_loss.png}
  \caption{Contrastive loss}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/tri_loss.png}
   \caption{Triplet loss}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/tri_loss_2.png}
   \caption{Transfer Learning and triplet loss}
   \label{fig:tri_loss_2}
  \end{subfigure}
  \hfill
    \caption{Training loss of the three implementations of the siamese network.}
    \label{fig:siatrainloss}
\end{figure}

\subsubsection{Comparison}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/acc_ter.png}
  \caption{Accuracy comparison}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/time_ter.png}
   \caption{Time taken comparison}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \caption{Comparison of the three implementations of the transfer learning.}
    \label{fig:siatrainloss}
\end{figure}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/acc_sia.png}
  \caption{Accuracy comparison}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/time_sia.png}
   \caption{Time taken comparison}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \caption{Comparison of the three implementations of the siamese network.}
    \label{fig:siatrainloss}
\end{figure}


\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/acc.png}
  \caption{Accuracy comparison}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/time.png}
   \caption{Time taken comparison}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \caption{Comparison of the two best implementations.}
    \label{fig:siatrainloss}
\end{figure}


\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.48\linewidth}
  \includegraphics[width=\linewidth]{figs/umab_visualT2.png}
  \caption{Xception + Siamese (T2)}
  \label{fig:con_loss}
  \end{subfigure}
  \hfill
   \begin{subfigure}[b]{0.48\linewidth}
   \includegraphics[width=\linewidth]{figs/umab_visualS2.png}
   \caption{Siamese all(S2)}
   \label{fig:tri_loss}
  \end{subfigure}
    \hfill
    \caption{visualization of embedded test data projected to 2D space 	with UMAP using  https://projector.tensorflow.org/.}
    \label{fig:2Dprojection}
\end{figure}




In our implementation, we observe that the triplet loss a little outperforms the contrastive loss. The possible reasons could be the triplet loss tries to be less greedy than contrastive loss since the distance is a relative concept. The triplet loss tries to bring the positive sample closer while also pushing away the negative sample when compared with an anchor, as shown in the figure \ref{fig:tripletloss}. In doing so, the model can clear know if the distance between the anchor sample and positive sample is smaller than the distance between the anchor and negative one. On the other hand, the contrastive loss, only considers one pair at a time, either positive or negative, so in a sense, it is more greedy. It's hard to ensure the similar objects are close enough. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/tripletloss.png}
  \caption{The Triplet Loss minimizes the distance between an anchor and a positive, and maximizes the distance between the anchor and a negative.}
  \label{fig:tripletloss}
\end{figure}


Furthermore, we can also compute the similarity between image pairs, as shown in figure \ref{}. Note that the smaller distance between the two images means they are more similar to each other. For example, in the figure, the distance between the first pair is 0.12, and it turns out that they belong to the same class Slippers. As for the second pair, the class of left image is Slippers and the class of right image is Sandals. The distance between them is 0.56, which is much larger than the first pair, as we expected. 

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/similarity.png}
  \caption{Examples of calculating the similarity of image pairs.}
  \label{fig:similarity}
\end{figure}


